{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cbor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104987c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cbor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531da58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"data/tangerine-project-1-export\"  # 根据需要改\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"training\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dfd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    values: shape (T, 9) 的 IMU+角度数据\n",
    "    返回: shape (75,) 的 float32 特征向量\n",
    "    \"\"\"\n",
    "    v = values.astype(np.float32)\n",
    "    T, D = v.shape\n",
    "    assert D == 9, f\"期望 9 维通道，实际 {D}\"\n",
    "\n",
    "    feats = []\n",
    "\n",
    "    # 1) 全局 mean / std / min / max -> 9 * 4 = 36\n",
    "    means = v.mean(axis=0)\n",
    "    stds  = v.std(axis=0)\n",
    "    mins  = v.min(axis=0)\n",
    "    maxs  = v.max(axis=0)\n",
    "\n",
    "    feats.extend(list(means))\n",
    "    feats.extend(list(stds))\n",
    "    feats.extend(list(mins))\n",
    "    feats.extend(list(maxs))   # 这里累计 36 维\n",
    "\n",
    "    # 2) 时间分三段，每段算 mean -> 3 * 9 = 27，累计 63 维\n",
    "    segments = np.array_split(v, 3, axis=0)\n",
    "    for seg in segments:\n",
    "        seg_mean = seg.mean(axis=0)\n",
    "        feats.extend(list(seg_mean))\n",
    "\n",
    "    # 3) 每个通道的 energy（均方）-> 9 维，累计 72 维\n",
    "    energy = (v ** 2).mean(axis=0)\n",
    "    feats.extend(list(energy))\n",
    "\n",
    "    # 4) 三个向量模长的 RMS（accel/gyro/angle 三组）-> 3 维，总计 75\n",
    "    accel_mag = np.sqrt((v[:, 0:3] ** 2).sum(axis=1)).mean()  # ax,ay,az\n",
    "    gyro_mag  = np.sqrt((v[:, 3:6] ** 2).sum(axis=1)).mean()  # gx,gy,gz\n",
    "    ori_mag   = np.sqrt((v[:, 6:9] ** 2).sum(axis=1)).mean()  # roll,pitch,yaw\n",
    "\n",
    "    feats.extend([accel_mag, gyro_mag, ori_mag])\n",
    "\n",
    "    feats = np.array(feats, dtype=np.float32)\n",
    "    assert feats.shape[0] == 75, feats.shape\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da1d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(split_dir):\n",
    "    X_list = []\n",
    "    label_name_list = []\n",
    "    file_list = sorted(glob.glob(os.path.join(split_dir, \"*.cbor\")))\n",
    "    print(f\"{split_dir} 里找到 {len(file_list)} 个 .cbor 文件\")\n",
    "\n",
    "    for path in file_list:\n",
    "        fname = os.path.basename(path)\n",
    "        # 文件名前缀作为类别名，例如 \"circle.xxx.cbor\" -> \"circle\"\n",
    "        label_name = fname.split(\".\")[0]\n",
    "\n",
    "        with open(path, \"rb\") as f:\n",
    "            msg = cbor2.load(f)\n",
    "\n",
    "        payload = msg[\"payload\"]\n",
    "        values = np.array(payload[\"values\"], dtype=np.float32)  # (T, 9)\n",
    "\n",
    "        feats = extract_features(values)  # (75,)\n",
    "        X_list.append(feats)\n",
    "        label_name_list.append(label_name)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)                     # (N, 75)\n",
    "    label_names = np.array(label_name_list)          # (N,)\n",
    "    return X, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aebd3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tangerine-project-1-export/training 里找到 225 个 .cbor 文件\n",
      "data/tangerine-project-1-export/testing 里找到 58 个 .cbor 文件\n",
      "trainval shape: (225, 75)\n",
      "test shape: (58, 75)\n",
      "trainval labels example: ['circle' 'other' 'peak' 'wave']\n",
      "test labels example: ['circle' 'other' 'peak' 'wave']\n"
     ]
    }
   ],
   "source": [
    "X_trainval, label_names_trainval = load_split(TRAIN_DIR)\n",
    "X_test,     label_names_test     = load_split(TEST_DIR)\n",
    "\n",
    "print(\"trainval shape:\", X_trainval.shape)\n",
    "print(\"test shape:\", X_test.shape)\n",
    "print(\"trainval labels example:\", np.unique(label_names_trainval))\n",
    "print(\"test labels example:\", np.unique(label_names_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9697d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别映射：\n",
      "  0 -> circle\n",
      "  1 -> other\n",
      "  2 -> peak\n",
      "  3 -> wave\n",
      "classes_cnt = 4\n"
     ]
    }
   ],
   "source": [
    "# 所有出现过的类别名\n",
    "all_label_names = sorted(set(label_names_trainval.tolist() + \n",
    "                             label_names_test.tolist()))\n",
    "label2id = {name: i for i, name in enumerate(all_label_names)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "print(\"类别映射：\")\n",
    "for name, idx in label2id.items():\n",
    "    print(f\"  {idx} -> {name}\")\n",
    "\n",
    "classes_cnt = len(all_label_names)\n",
    "print(\"classes_cnt =\", classes_cnt)\n",
    "\n",
    "# 映射到 int 标签\n",
    "y_trainval = np.array([label2id[n] for n in label_names_trainval], dtype=np.int32)\n",
    "y_test     = np.array([label2id[n] for n in label_names_test],     dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a18bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cnt      = 180\n",
      "validation_cnt = 45\n",
      "test_cnt       = 58\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "N = len(X_trainval)\n",
    "indices = np.arange(N)\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X_trainval = X_trainval[indices]\n",
    "y_trainval = y_trainval[indices]\n",
    "\n",
    "train_cnt = int(0.8 * N)\n",
    "val_cnt   = N - train_cnt\n",
    "\n",
    "X_train = X_trainval[:train_cnt]\n",
    "y_train = y_trainval[:train_cnt]\n",
    "X_val   = X_trainval[train_cnt:]\n",
    "y_val   = y_trainval[train_cnt:]\n",
    "\n",
    "print(\"train_cnt      =\", len(X_train))\n",
    "print(\"validation_cnt =\", len(X_val))\n",
    "print(\"test_cnt       =\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f69cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_int_array(y: np.ndarray, var_name: str) -> str:\n",
    "    vals = \", \".join(str(int(v)) for v in y)\n",
    "    return f\"const int {var_name}[{len(y)}] = {{ {vals} }};\\n\"\n",
    "\n",
    "def format_2d_float_array(X: np.ndarray, var_name: str) -> str:\n",
    "    n_samples, n_feats = X.shape\n",
    "    lines = []\n",
    "    lines.append(f\"const float {var_name}[{n_samples}][{n_feats}] = {{\")\n",
    "    for row in X:\n",
    "        row_str = \", \".join(f\"{float(v):.6f}f\" for v in row)\n",
    "        lines.append(f\"  {{ {row_str} }},\")\n",
    "    lines.append(\"};\\n\")\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已生成 data.h\n"
     ]
    }
   ],
   "source": [
    "first_layer_input_cnt = X_train.shape[1]\n",
    "\n",
    "header_lines = []\n",
    "\n",
    "header_lines.append(\"// Auto-generated data file for on-device training\\n\")\n",
    "header_lines.append(\"#ifndef DATA_H\")\n",
    "header_lines.append(\"#define DATA_H\\n\")\n",
    "\n",
    "header_lines.append(f\"const int first_layer_input_cnt = {first_layer_input_cnt};\")\n",
    "header_lines.append(f\"const int train_data_cnt        = {len(X_train)};\")\n",
    "header_lines.append(f\"const int validation_data_cnt   = {len(X_val)};\")\n",
    "header_lines.append(f\"const int test_data_cnt         = {len(X_test)};\")\n",
    "header_lines.append(f\"const int classes_cnt           = {classes_cnt};\\n\")\n",
    "\n",
    "header_lines.append(\"// Label mapping:\")\n",
    "for idx in range(classes_cnt):\n",
    "    header_lines.append(f\"//   {idx} -> {id2label[idx]}\")\n",
    "header_lines.append(\"\")\n",
    "\n",
    "# 标签数组\n",
    "header_lines.append(format_int_array(y_train, \"train_labels\"))\n",
    "header_lines.append(format_int_array(y_val, \"validation_labels\"))\n",
    "header_lines.append(format_int_array(y_test, \"test_labels\"))\n",
    "\n",
    "# 特征数据数组\n",
    "header_lines.append(format_2d_float_array(X_train, \"train_data\"))\n",
    "header_lines.append(format_2d_float_array(X_val,   \"validation_data\"))\n",
    "header_lines.append(format_2d_float_array(X_test,  \"test_data\"))\n",
    "\n",
    "header_lines.append(\"#endif // DATA_H\\n\")\n",
    "\n",
    "data_h_text = \"\\n\".join(header_lines)\n",
    "\n",
    "with open(\"data/data.h\", \"w\") as f:\n",
    "    f.write(data_h_text)\n",
    "\n",
    "print(\"✅ 已生成 data.h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf70cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9851583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
