{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cbor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104987c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cbor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531da58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"jiuenfeng-project-1-export\"  # 根据需要改\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"training\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dfd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    values: shape (T, 9) 的 IMU+角度数据\n",
    "    返回: shape (75,) 的 float32 特征向量\n",
    "    \"\"\"\n",
    "    v = values.astype(np.float32)\n",
    "    T, D = v.shape\n",
    "    assert D == 9, f\"期望 9 维通道，实际 {D}\"\n",
    "\n",
    "    feats = []\n",
    "\n",
    "    # 1) 全局 mean / std / min / max -> 9 * 4 = 36\n",
    "    means = v.mean(axis=0)\n",
    "    stds  = v.std(axis=0)\n",
    "    mins  = v.min(axis=0)\n",
    "    maxs  = v.max(axis=0)\n",
    "\n",
    "    feats.extend(list(means))\n",
    "    feats.extend(list(stds))\n",
    "    feats.extend(list(mins))\n",
    "    feats.extend(list(maxs))   # 这里累计 36 维\n",
    "\n",
    "    # 2) 时间分三段，每段算 mean -> 3 * 9 = 27，累计 63 维\n",
    "    segments = np.array_split(v, 3, axis=0)\n",
    "    for seg in segments:\n",
    "        seg_mean = seg.mean(axis=0)\n",
    "        feats.extend(list(seg_mean))\n",
    "\n",
    "    # 3) 每个通道的 energy（均方）-> 9 维，累计 72 维\n",
    "    energy = (v ** 2).mean(axis=0)\n",
    "    feats.extend(list(energy))\n",
    "\n",
    "    # 4) 三个向量模长的 RMS（accel/gyro/angle 三组）-> 3 维，总计 75\n",
    "    accel_mag = np.sqrt((v[:, 0:3] ** 2).sum(axis=1)).mean()  # ax,ay,az\n",
    "    gyro_mag  = np.sqrt((v[:, 3:6] ** 2).sum(axis=1)).mean()  # gx,gy,gz\n",
    "    ori_mag   = np.sqrt((v[:, 6:9] ** 2).sum(axis=1)).mean()  # roll,pitch,yaw\n",
    "\n",
    "    feats.extend([accel_mag, gyro_mag, ori_mag])\n",
    "\n",
    "    feats = np.array(feats, dtype=np.float32)\n",
    "    assert feats.shape[0] == 75, feats.shape\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da1d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(split_dir):\n",
    "    X_list = []\n",
    "    label_name_list = []\n",
    "    file_list = sorted(glob.glob(os.path.join(split_dir, \"*.cbor\")))\n",
    "    print(f\"{split_dir} 里找到 {len(file_list)} 个 .cbor 文件\")\n",
    "\n",
    "    for path in file_list:\n",
    "        fname = os.path.basename(path)\n",
    "        # 文件名前缀作为类别名，例如 \"circle.xxx.cbor\" -> \"circle\"\n",
    "        label_name = fname.split(\".\")[0]\n",
    "        if label_name == \"noise\":\n",
    "            label_name = \"other\"\n",
    "\n",
    "        with open(path, \"rb\") as f:\n",
    "            msg = cbor2.load(f)\n",
    "\n",
    "        payload = msg[\"payload\"]\n",
    "        values = np.array(payload[\"values\"], dtype=np.float32)  # (T, 9)\n",
    "\n",
    "        feats = extract_features(values)  # (75,)\n",
    "        X_list.append(feats)\n",
    "        label_name_list.append(label_name)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)                     # (N, 75)\n",
    "    label_names = np.array(label_name_list)          # (N,)\n",
    "    return X, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aebd3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiuenfeng-project-1-export\\training 里找到 240 个 .cbor 文件\n",
      "jiuenfeng-project-1-export\\testing 里找到 28 个 .cbor 文件\n",
      "trainval shape: (240, 75)\n",
      "test shape: (28, 75)\n",
      "trainval labels example: ['circle' 'other' 'peak' 'wave']\n",
      "test labels example: ['circle' 'other' 'peak' 'wave']\n"
     ]
    }
   ],
   "source": [
    "X_trainval, label_names_trainval = load_split(TRAIN_DIR)\n",
    "X_test,     label_names_test     = load_split(TEST_DIR)\n",
    "\n",
    "print(\"trainval shape:\", X_trainval.shape)\n",
    "print(\"test shape:\", X_test.shape)\n",
    "print(\"trainval labels example:\", np.unique(label_names_trainval))\n",
    "print(\"test labels example:\", np.unique(label_names_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9697d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别映射：\n",
      "  0 -> circle\n",
      "  1 -> other\n",
      "  2 -> peak\n",
      "  3 -> wave\n",
      "classes_cnt = 4\n"
     ]
    }
   ],
   "source": [
    "# 所有出现过的类别名\n",
    "all_label_names = sorted(set(label_names_trainval.tolist() + \n",
    "                             label_names_test.tolist()))\n",
    "label2id = {name: i for i, name in enumerate(all_label_names)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "print(\"类别映射：\")\n",
    "for name, idx in label2id.items():\n",
    "    print(f\"  {idx} -> {name}\")\n",
    "\n",
    "classes_cnt = len(all_label_names)\n",
    "print(\"classes_cnt =\", classes_cnt)\n",
    "\n",
    "# 映射到 int 标签\n",
    "y_trainval = np.array([label2id[n] for n in label_names_trainval], dtype=np.int32)\n",
    "y_test     = np.array([label2id[n] for n in label_names_test],     dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a18bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cnt      = 192\n",
      "validation_cnt = 48\n",
      "test_cnt       = 28\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "N = len(X_trainval)\n",
    "indices = np.arange(N)\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X_trainval = X_trainval[indices]\n",
    "y_trainval = y_trainval[indices]\n",
    "\n",
    "train_cnt = int(0.8 * N)\n",
    "val_cnt   = N - train_cnt\n",
    "\n",
    "X_train = X_trainval[:train_cnt]\n",
    "y_train = y_trainval[:train_cnt]\n",
    "X_val   = X_trainval[train_cnt:]\n",
    "y_val   = y_trainval[train_cnt:]\n",
    "\n",
    "print(\"train_cnt      =\", len(X_train))\n",
    "print(\"validation_cnt =\", len(X_val))\n",
    "print(\"test_cnt       =\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f69cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float_array(arr: np.ndarray, var_name: str) -> str:\n",
    "    # 将 float 数组格式化为 C 语言的 float 数组\n",
    "    vals = \", \".join(f\"{v:.6f}f\" for v in arr)\n",
    "    return f\"const float {var_name}[{len(arr)}] = {{ {vals} }};\\\\n\"\n",
    "\n",
    "def format_int_array(y: np.ndarray, var_name: str) -> str:\n",
    "    vals = \", \".join(str(int(v)) for v in y)\n",
    "    return f\"const int {var_name}[{len(y)}] = {{ {vals} }};\\n\"\n",
    "\n",
    "def format_2d_float_array(X: np.ndarray, var_name: str) -> str:\n",
    "    n_samples, n_feats = X.shape\n",
    "    lines = []\n",
    "    lines.append(f\"const float {var_name}[{n_samples}][{n_feats}] = {{\")\n",
    "    for row in X:\n",
    "        row_str = \", \".join(f\"{float(v):.6f}f\" for v in row)\n",
    "        lines.append(f\"  {{ {row_str} }},\")\n",
    "    lines.append(\"};\\n\")\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4c6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min vector shape: (75,)\n",
      "Max vector shape: (75,)\n",
      "✅ 已生成 data.h (包含 feature_min 和 feature_max)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 计算归一化参数 (只基于训练集!) ---\n",
    "# axis=0 表示沿着样本维度计算，得到每个特征(75维)的最小值和最大值\n",
    "feature_min = X_train.min(axis=0)\n",
    "feature_max = X_train.max(axis=0)\n",
    "\n",
    "print(\"Min vector shape:\", feature_min.shape)\n",
    "print(\"Max vector shape:\", feature_max.shape)\n",
    "# 简单的检查，防止由静止数据导致的 max == min (除以0风险)\n",
    "# 如果 max == min，我们在 max 上加一点点 epsilon\n",
    "eps = 1e-6\n",
    "same_val_indices = (feature_max - feature_min) < eps\n",
    "if np.any(same_val_indices):\n",
    "    print(f\"注意: 有 {np.sum(same_val_indices)} 个特征是常量，已微调 max 值以避免除零。\")\n",
    "    feature_max[same_val_indices] += eps\n",
    "\n",
    "\n",
    "# --- 2. 生成 data.h 内容 ---\n",
    "first_layer_input_cnt = X_train.shape[1]\n",
    "\n",
    "header_lines = []\n",
    "\n",
    "header_lines.append(\"// Auto-generated data file for on-device training\\n\")\n",
    "header_lines.append(\"#ifndef DATA_H\")\n",
    "header_lines.append(\"#define DATA_H\\n\")\n",
    "\n",
    "header_lines.append(f\"const int first_layer_input_cnt = {first_layer_input_cnt};\")\n",
    "header_lines.append(f\"const int train_data_cnt        = {len(X_train)};\")\n",
    "header_lines.append(f\"const int validation_data_cnt   = {len(X_val)};\")\n",
    "header_lines.append(f\"const int test_data_cnt         = {len(X_test)};\")\n",
    "header_lines.append(f\"const int classes_cnt           = {classes_cnt};\\n\")\n",
    "\n",
    "header_lines.append(\"// Label mapping:\")\n",
    "for idx in range(classes_cnt):\n",
    "    header_lines.append(f\"//   {idx} -> {id2label[idx]}\")\n",
    "header_lines.append(\"\")\n",
    "\n",
    "# --- 新增: 写入归一化参数 ---\n",
    "header_lines.append(\"// Normalization parameters (Min-Max from Training Set)\")\n",
    "header_lines.append(format_float_array(feature_min, \"feature_min\"))\n",
    "header_lines.append(format_float_array(feature_max, \"feature_max\"))\n",
    "header_lines.append(\"\")\n",
    "\n",
    "# 标签数组\n",
    "header_lines.append(format_int_array(y_train, \"train_labels\"))\n",
    "header_lines.append(format_int_array(y_val, \"validation_labels\"))\n",
    "header_lines.append(format_int_array(y_test, \"test_labels\"))\n",
    "\n",
    "# 特征数据数组 (保持原始数据 RAW，让板子去归一化，或者你也可以在这里预处理好)\n",
    "# 建议: 保持 RAW 数据导出，让板子用 feature_min/max 归一化 input buffer\n",
    "# 这样板子在 Inference 时逻辑是一样的 (Raw Sensor -> Normalize -> Predict)\n",
    "header_lines.append(format_2d_float_array(X_train, \"train_data\"))\n",
    "header_lines.append(format_2d_float_array(X_val,   \"validation_data\"))\n",
    "header_lines.append(format_2d_float_array(X_test,  \"test_data\"))\n",
    "\n",
    "header_lines.append(\"#endif // DATA_H\\n\")\n",
    "\n",
    "data_h_text = \"\\n\".join(header_lines)\n",
    "\n",
    "with open(\"data.h\", \"w\") as f:\n",
    "    f.write(data_h_text)\n",
    "\n",
    "print(\"✅ 已生成 data.h (包含 feature_min 和 feature_max)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
